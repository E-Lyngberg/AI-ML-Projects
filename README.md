# AI-ML-Projects
A repository to store links to relevant AI-ML projects that I have contributed to or written myself over the last few years. Most of these are stored in google colab notebooks that can be accessed via the links provided.


## Star Trek Neural Network

In a Computational Data Analytics course taken my sophomore year of undergraduate studies I was tasked with broad creative allowance to build a machine learning model to perform a task. My group member and I decided that it would be both fun and a great exploration of image preprocessing and analysis techniques to build a convolutional neural network to classify Star Trek ships based on their faction. This endeavour turned out to be more educational than anticipated, as we came to realize that the preprocessing of the images that we sourced from various Star Trek fan websites was more important than the complexity of the Neural Network itself. 

[Star Trek Neural Network and Image Edge Detection via Sobel Filter](https://colab.research.google.com/drive/1R6SccjWHyJ_9DNzcatDPD_WzPjBQJ25F?usp=sharing)

## Autoencoder for Encoding and Decoding 3D Objects and Anomaly Detection in Lung Scans

In a Mathematical Methods in Data Science course taken in my senior year of undergraduate studies, a fellow student and I built an autoencoder to learn more about the abilities of autoencoders to be used for encoding and decoding data with various latent layers. Depending on the depth of the autoencoder, one can retain as much as or as little latent information regarding the original dataset as needed. We have shown through this work that with a latent representation that is much smaller than the original data we can still retain most of the necessary information to reconstruct the original 3-D object and have it still be completely recognizable by a human. This type of latent information analysis will only become more and more important with future iterations of generative AI models, as the scaling required in deep understanding of natural language, images, etc. will require us to be able represent them with much less data than the original files in order to make computation more efficient.

[Autoencoder Exploration on Simulated Data for 3 Dimensional Swiss Roll and S-Curve](https://colab.research.google.com/drive/1NWcY2Jhzax_7BAAGwZw_HBeM7jHc0Y_X?usp=sharing)

